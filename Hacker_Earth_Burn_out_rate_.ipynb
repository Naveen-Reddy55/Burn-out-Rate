{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Hacker_Earth_Burn_out_rate .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3jY5ERf0uEG",
        "outputId": "991ee672-3d68-415b-c6e1-08c8681e8c38",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "train_upload=files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6b07ab79-2a2b-46e9-baf8-2e270e7bf020\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6b07ab79-2a2b-46e9-baf8-2e270e7bf020\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_sJ_B_D1LF6"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltKDth-Z12Rl",
        "outputId": "a2f263e4-d7fc-4928-b127-b66607fb78ee",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "test_upload=files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89c3c7c6-806d-438e-9625-00bc7b99ba47\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89c3c7c6-806d-438e-9625-00bc7b99ba47\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhvSkk_618P7"
      },
      "source": [
        "train_data=pd.read_csv(io.BytesIO(train_upload[\"train.csv\"]))\n",
        "test_data=pd.read_csv(io.BytesIO(test_upload[\"test.csv\"]))"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvrLq3c72YX9",
        "outputId": "636fa4b6-3f9b-46f0-ee29-3c8c346d0bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_data.head()\n",
        "test_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Employee ID</th>\n",
              "      <th>Date of Joining</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Company Type</th>\n",
              "      <th>WFH Setup Available</th>\n",
              "      <th>Designation</th>\n",
              "      <th>Resource Allocation</th>\n",
              "      <th>Mental Fatigue Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fffe31003300390039003000</td>\n",
              "      <td>2008-12-10</td>\n",
              "      <td>Female</td>\n",
              "      <td>Service</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fffe31003300310037003800</td>\n",
              "      <td>2008-08-14</td>\n",
              "      <td>Female</td>\n",
              "      <td>Product</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fffe33003400380035003900</td>\n",
              "      <td>2008-11-13</td>\n",
              "      <td>Male</td>\n",
              "      <td>Product</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fffe3100370039003200</td>\n",
              "      <td>2008-02-07</td>\n",
              "      <td>Female</td>\n",
              "      <td>Service</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fffe32003600390036003700</td>\n",
              "      <td>2008-07-17</td>\n",
              "      <td>Female</td>\n",
              "      <td>Product</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Employee ID  ... Mental Fatigue Score\n",
              "0  fffe31003300390039003000  ...                  7.7\n",
              "1  fffe31003300310037003800  ...                  5.2\n",
              "2  fffe33003400380035003900  ...                  5.9\n",
              "3      fffe3100370039003200  ...                  4.6\n",
              "4  fffe32003600390036003700  ...                  6.4\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0osMh6x2bd5",
        "outputId": "a16f0316-6ff8-4438-9f98-f8ca86c429aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data.isnull().sum()\n",
        "test_data.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Employee ID             0\n",
              "Date of Joining         0\n",
              "Gender                  0\n",
              "Company Type            0\n",
              "WFH Setup Available     0\n",
              "Designation             0\n",
              "Resource Allocation     0\n",
              "Mental Fatigue Score    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Mqhwsh-0gL",
        "outputId": "1cd34dc1-6ba8-4be6-fb5e-794f926b3a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12250, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMDXuBOb37P3",
        "outputId": "aded383a-c79a-4429-bc3c-67908da5d23b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22750, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEpQzxPS2xUP",
        "outputId": "627faf3d-9961-4a91-d7bd-995adf5a4ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "train_data[\"Resource Allocation\"].fillna(int(train_data[\"Resource Allocation\"].mean()),inplace=True)\n",
        "train_data[\"Mental Fatigue Score\"].fillna(int(train_data[\"Mental Fatigue Score\"].mean()),inplace=True)\n",
        "train_data[\"Burn Rate\"].fillna(int(train_data[\"Burn Rate\"].mean()),inplace=True)\n",
        "train_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Employee ID</th>\n",
              "      <th>Date of Joining</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Company Type</th>\n",
              "      <th>WFH Setup Available</th>\n",
              "      <th>Designation</th>\n",
              "      <th>Resource Allocation</th>\n",
              "      <th>Mental Fatigue Score</th>\n",
              "      <th>Burn Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fffe32003000360033003200</td>\n",
              "      <td>2008-09-30</td>\n",
              "      <td>Female</td>\n",
              "      <td>Service</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fffe3700360033003500</td>\n",
              "      <td>2008-11-30</td>\n",
              "      <td>Male</td>\n",
              "      <td>Service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fffe31003300320037003900</td>\n",
              "      <td>2008-03-10</td>\n",
              "      <td>Female</td>\n",
              "      <td>Product</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fffe32003400380032003900</td>\n",
              "      <td>2008-11-03</td>\n",
              "      <td>Male</td>\n",
              "      <td>Service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fffe31003900340031003600</td>\n",
              "      <td>2008-07-24</td>\n",
              "      <td>Female</td>\n",
              "      <td>Service</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22745</th>\n",
              "      <td>fffe31003500370039003100</td>\n",
              "      <td>2008-12-30</td>\n",
              "      <td>Female</td>\n",
              "      <td>Service</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22746</th>\n",
              "      <td>fffe33003000350031003800</td>\n",
              "      <td>2008-01-19</td>\n",
              "      <td>Female</td>\n",
              "      <td>Product</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22747</th>\n",
              "      <td>fffe390032003000</td>\n",
              "      <td>2008-11-05</td>\n",
              "      <td>Male</td>\n",
              "      <td>Service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22748</th>\n",
              "      <td>fffe33003300320036003900</td>\n",
              "      <td>2008-01-10</td>\n",
              "      <td>Female</td>\n",
              "      <td>Service</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22749</th>\n",
              "      <td>fffe3400350031003800</td>\n",
              "      <td>2008-01-06</td>\n",
              "      <td>Male</td>\n",
              "      <td>Product</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0.61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22750 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Employee ID  ... Burn Rate\n",
              "0      fffe32003000360033003200  ...      0.16\n",
              "1          fffe3700360033003500  ...      0.36\n",
              "2      fffe31003300320037003900  ...      0.49\n",
              "3      fffe32003400380032003900  ...      0.20\n",
              "4      fffe31003900340031003600  ...      0.52\n",
              "...                         ...  ...       ...\n",
              "22745  fffe31003500370039003100  ...      0.41\n",
              "22746  fffe33003000350031003800  ...      0.59\n",
              "22747          fffe390032003000  ...      0.72\n",
              "22748  fffe33003300320036003900  ...      0.52\n",
              "22749      fffe3400350031003800  ...      0.61\n",
              "\n",
              "[22750 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1te7TED4-_d",
        "outputId": "43133963-35a6-4e4f-b166-1596b7928e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Employee ID             0\n",
              "Date of Joining         0\n",
              "Gender                  0\n",
              "Company Type            0\n",
              "WFH Setup Available     0\n",
              "Designation             0\n",
              "Resource Allocation     0\n",
              "Mental Fatigue Score    0\n",
              "Burn Rate               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "694-KbTG5DHa",
        "outputId": "88d9bb35-f55d-49b2-cf65-e5e97457b6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_data.drop(([\"Date of Joining\",\"Employee ID\",\"Company Type\"]),inplace=True,axis=1)\n",
        "test_data.drop(([\"Date of Joining\",\"Employee ID\",\"Company Type\"]),inplace=True,axis=1)\n",
        "test_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>WFH Setup Available</th>\n",
              "      <th>Designation</th>\n",
              "      <th>Resource Allocation</th>\n",
              "      <th>Mental Fatigue Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12245</th>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12246</th>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12247</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12248</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12249</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12250 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Gender WFH Setup Available  ...  Resource Allocation  Mental Fatigue Score\n",
              "0      Female                  No  ...                  5.0                   7.7\n",
              "1      Female                 Yes  ...                  2.0                   5.2\n",
              "2        Male                 Yes  ...                  3.0                   5.9\n",
              "3      Female                  No  ...                  6.0                   4.6\n",
              "4      Female                  No  ...                  5.0                   6.4\n",
              "...       ...                 ...  ...                  ...                   ...\n",
              "12245  Female                 Yes  ...                  2.0                   6.1\n",
              "12246  Female                 Yes  ...                  4.0                   5.9\n",
              "12247    Male                  No  ...                  7.0                   9.6\n",
              "12248    Male                  No  ...                  6.0                   6.7\n",
              "12249  Female                  No  ...                  2.0                   2.0\n",
              "\n",
              "[12250 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo8unWTb5wwM"
      },
      "source": [
        "train_gender_dummies=pd.get_dummies(train_data[\"Gender\"],drop_first=True)\n",
        "train_gender_dummies.rename(columns={\"Male\":\"Sex\"},inplace=True)\n",
        "test_gender_dummies=pd.get_dummies(test_data[\"Gender\"],drop_first=True)\n",
        "test_gender_dummies.rename(columns={\"Male\":\"Sex\"},inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAaGVjtC7s7v",
        "outputId": "89f45001-9419-455f-a037-56597a878179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_WFH_Setup_Available_dummies=pd.get_dummies(train_data[\"WFH Setup Available\"],drop_first=True)\n",
        "train_WFH_Setup_Available_dummies.rename(columns={\"Yes\":\"WFH Setup Available value\"},inplace=True)\n",
        "test_WFH_Setup_Available_dummies=pd.get_dummies(test_data[\"WFH Setup Available\"],drop_first=True)\n",
        "test_WFH_Setup_Available_dummies.rename(columns={\"Yes\":\"WFH Setup Available value\"},inplace=True)\n",
        "test_WFH_Setup_Available_dummies"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WFH Setup Available value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12245</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12246</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12247</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12248</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12249</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12250 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       WFH Setup Available value\n",
              "0                              0\n",
              "1                              1\n",
              "2                              1\n",
              "3                              0\n",
              "4                              0\n",
              "...                          ...\n",
              "12245                          1\n",
              "12246                          1\n",
              "12247                          0\n",
              "12248                          0\n",
              "12249                          0\n",
              "\n",
              "[12250 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPIfcOUr8iaa",
        "outputId": "ca63d912-fffa-4938-b881-277280f4abe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "train_main_data_set=pd.concat([train_data,train_WFH_Setup_Available_dummies,train_gender_dummies],axis=1)\n",
        "test_main_data_set=pd.concat([test_data,test_WFH_Setup_Available_dummies,test_gender_dummies],axis=1)\n",
        "test_main_data_set"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>WFH Setup Available</th>\n",
              "      <th>Designation</th>\n",
              "      <th>Resource Allocation</th>\n",
              "      <th>Mental Fatigue Score</th>\n",
              "      <th>WFH Setup Available value</th>\n",
              "      <th>Sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12245</th>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12246</th>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12247</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12248</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12249</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12250 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Gender WFH Setup Available  ...  WFH Setup Available value  Sex\n",
              "0      Female                  No  ...                          0    0\n",
              "1      Female                 Yes  ...                          1    0\n",
              "2        Male                 Yes  ...                          1    1\n",
              "3      Female                  No  ...                          0    0\n",
              "4      Female                  No  ...                          0    0\n",
              "...       ...                 ...  ...                        ...  ...\n",
              "12245  Female                 Yes  ...                          1    0\n",
              "12246  Female                 Yes  ...                          1    0\n",
              "12247    Male                  No  ...                          0    1\n",
              "12248    Male                  No  ...                          0    1\n",
              "12249  Female                  No  ...                          0    0\n",
              "\n",
              "[12250 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYIMiD2T9QYH"
      },
      "source": [
        "train_main_data_set.drop([\"Gender\",\"WFH Setup Available\"],axis=1,inplace=True)\n",
        "test_main_data_set.drop([\"Gender\",\"WFH Setup Available\"],axis=1,inplace=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--fbhLhe9blm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH5wlqdI9TKu",
        "outputId": "36566d0d-014b-4db9-95ea-92e342129fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_score=train_main_data_set[\"Burn Rate\"]\n",
        "train_data_set=train_main_data_set.drop(([\"Burn Rate\"]),axis=1)\n",
        "train_data_set\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Designation</th>\n",
              "      <th>Resource Allocation</th>\n",
              "      <th>Mental Fatigue Score</th>\n",
              "      <th>WFH Setup Available value</th>\n",
              "      <th>Sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22745</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22746</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22747</th>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22748</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22749</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22750 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Designation  Resource Allocation  ...  WFH Setup Available value  Sex\n",
              "0              2.0                  3.0  ...                          0    0\n",
              "1              1.0                  2.0  ...                          1    1\n",
              "2              2.0                  4.0  ...                          1    0\n",
              "3              1.0                  1.0  ...                          1    1\n",
              "4              3.0                  7.0  ...                          0    0\n",
              "...            ...                  ...  ...                        ...  ...\n",
              "22745          1.0                  3.0  ...                          0    0\n",
              "22746          3.0                  6.0  ...                          1    0\n",
              "22747          3.0                  7.0  ...                          1    1\n",
              "22748          2.0                  5.0  ...                          0    0\n",
              "22749          3.0                  6.0  ...                          0    1\n",
              "\n",
              "[22750 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUnIVUVk99oj"
      },
      "source": [
        "only_train_data,val_data,only_train_score,val_burn_rate=train_test_split(train_data_set, train_score, test_size=0.20, shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhE0xWRUgu_H",
        "outputId": "c8f6c191-a1f4-4aa1-93bc-df47fb65b5fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_burn_rate.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4550,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CrkSncz7HU1"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler=StandardScaler()\n",
        "only_train_data=scaler.fit_transform(only_train_data)\n",
        "val_data=scaler.transform(val_data)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFNSzl3cBVl-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agw2bRy6YNB7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmkt_Wa9B5Tu",
        "outputId": "b943b354-55b9-4b5d-90f6-521d920a3e36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(128,activation=\"relu\",input_shape=(train_data_set.shape[1],)))\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1,activation=\"linear\"))\n",
        "model.summary()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_80 (Dense)             (None, 128)               768       \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 166,657\n",
            "Trainable params: 166,145\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RYAifHkDKF9"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"mean_absolute_error\",metrics=[\"mean_absolute_error\"])"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RwcbCNbDZRd",
        "outputId": "9294c631-ce56-4679-e823-12959cb52480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history=model.fit(x=only_train_data,y=only_train_score,epochs=500,validation_data=(val_data,val_burn_rate),)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.1329 - mean_absolute_error: 0.1329 - val_loss: 0.1376 - val_mean_absolute_error: 0.1376\n",
            "Epoch 2/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0863 - mean_absolute_error: 0.0863 - val_loss: 0.0956 - val_mean_absolute_error: 0.0956\n",
            "Epoch 3/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0848 - mean_absolute_error: 0.0848 - val_loss: 0.0858 - val_mean_absolute_error: 0.0858\n",
            "Epoch 4/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0839 - mean_absolute_error: 0.0839 - val_loss: 0.0891 - val_mean_absolute_error: 0.0891\n",
            "Epoch 5/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.1402 - val_mean_absolute_error: 0.1402\n",
            "Epoch 6/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0850 - mean_absolute_error: 0.0850 - val_loss: 0.1303 - val_mean_absolute_error: 0.1303\n",
            "Epoch 7/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.0771 - val_mean_absolute_error: 0.0771\n",
            "Epoch 8/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.0962 - val_mean_absolute_error: 0.0962\n",
            "Epoch 9/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_absolute_error: 0.0841 - val_loss: 0.0898 - val_mean_absolute_error: 0.0898\n",
            "Epoch 10/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.0805 - val_mean_absolute_error: 0.0805\n",
            "Epoch 11/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.1205 - val_mean_absolute_error: 0.1205\n",
            "Epoch 12/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.0947 - val_mean_absolute_error: 0.0947\n",
            "Epoch 13/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.1248 - val_mean_absolute_error: 0.1248\n",
            "Epoch 14/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0854 - mean_absolute_error: 0.0854 - val_loss: 0.1396 - val_mean_absolute_error: 0.1396\n",
            "Epoch 15/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0819 - mean_absolute_error: 0.0819 - val_loss: 0.1383 - val_mean_absolute_error: 0.1383\n",
            "Epoch 16/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.1267 - val_mean_absolute_error: 0.1267\n",
            "Epoch 17/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.1149 - val_mean_absolute_error: 0.1149\n",
            "Epoch 18/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0751 - val_mean_absolute_error: 0.0751\n",
            "Epoch 19/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0816 - val_mean_absolute_error: 0.0816\n",
            "Epoch 20/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_absolute_error: 0.0837 - val_loss: 0.1194 - val_mean_absolute_error: 0.1194\n",
            "Epoch 21/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
            "Epoch 22/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0809 - mean_absolute_error: 0.0809 - val_loss: 0.0975 - val_mean_absolute_error: 0.0975\n",
            "Epoch 23/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.0848 - val_mean_absolute_error: 0.0848\n",
            "Epoch 24/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_absolute_error: 0.0823 - val_loss: 0.1047 - val_mean_absolute_error: 0.1047\n",
            "Epoch 25/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0813 - mean_absolute_error: 0.0813 - val_loss: 0.1204 - val_mean_absolute_error: 0.1204\n",
            "Epoch 26/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0813 - mean_absolute_error: 0.0813 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
            "Epoch 27/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0819 - mean_absolute_error: 0.0819 - val_loss: 0.0960 - val_mean_absolute_error: 0.0960\n",
            "Epoch 28/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.0817 - val_mean_absolute_error: 0.0817\n",
            "Epoch 29/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0813 - mean_absolute_error: 0.0813 - val_loss: 0.1108 - val_mean_absolute_error: 0.1108\n",
            "Epoch 30/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0813 - mean_absolute_error: 0.0813 - val_loss: 0.0775 - val_mean_absolute_error: 0.0775\n",
            "Epoch 31/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0796 - mean_absolute_error: 0.0796 - val_loss: 0.0879 - val_mean_absolute_error: 0.0879\n",
            "Epoch 32/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_absolute_error: 0.0824 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
            "Epoch 33/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0810 - mean_absolute_error: 0.0810 - val_loss: 0.0752 - val_mean_absolute_error: 0.0752\n",
            "Epoch 34/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0808 - mean_absolute_error: 0.0808 - val_loss: 0.0965 - val_mean_absolute_error: 0.0965\n",
            "Epoch 35/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0807 - mean_absolute_error: 0.0807 - val_loss: 0.0968 - val_mean_absolute_error: 0.0968\n",
            "Epoch 36/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0811 - mean_absolute_error: 0.0811 - val_loss: 0.0772 - val_mean_absolute_error: 0.0772\n",
            "Epoch 37/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0801 - mean_absolute_error: 0.0801 - val_loss: 0.1085 - val_mean_absolute_error: 0.1085\n",
            "Epoch 38/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0803 - mean_absolute_error: 0.0803 - val_loss: 0.0797 - val_mean_absolute_error: 0.0797\n",
            "Epoch 39/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0799 - mean_absolute_error: 0.0799 - val_loss: 0.1071 - val_mean_absolute_error: 0.1071\n",
            "Epoch 40/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0803 - mean_absolute_error: 0.0803 - val_loss: 0.1190 - val_mean_absolute_error: 0.1190\n",
            "Epoch 41/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0814 - mean_absolute_error: 0.0814 - val_loss: 0.0837 - val_mean_absolute_error: 0.0837\n",
            "Epoch 42/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0807 - mean_absolute_error: 0.0807 - val_loss: 0.0741 - val_mean_absolute_error: 0.0741\n",
            "Epoch 43/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0803 - mean_absolute_error: 0.0803 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 44/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0794 - mean_absolute_error: 0.0794 - val_loss: 0.0858 - val_mean_absolute_error: 0.0858\n",
            "Epoch 45/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0799 - mean_absolute_error: 0.0799 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 46/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0803 - mean_absolute_error: 0.0803 - val_loss: 0.0786 - val_mean_absolute_error: 0.0786\n",
            "Epoch 47/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0805 - mean_absolute_error: 0.0805 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
            "Epoch 48/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0798 - mean_absolute_error: 0.0798 - val_loss: 0.0758 - val_mean_absolute_error: 0.0758\n",
            "Epoch 49/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0806 - mean_absolute_error: 0.0806 - val_loss: 0.0834 - val_mean_absolute_error: 0.0834\n",
            "Epoch 50/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0781 - mean_absolute_error: 0.0781 - val_loss: 0.0891 - val_mean_absolute_error: 0.0891\n",
            "Epoch 51/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0786 - mean_absolute_error: 0.0786 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 52/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0802 - mean_absolute_error: 0.0802 - val_loss: 0.0743 - val_mean_absolute_error: 0.0743\n",
            "Epoch 53/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0790 - mean_absolute_error: 0.0790 - val_loss: 0.0808 - val_mean_absolute_error: 0.0808\n",
            "Epoch 54/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0784 - mean_absolute_error: 0.0784 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
            "Epoch 55/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0795 - mean_absolute_error: 0.0795 - val_loss: 0.1057 - val_mean_absolute_error: 0.1057\n",
            "Epoch 56/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0787 - mean_absolute_error: 0.0787 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 57/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0784 - mean_absolute_error: 0.0784 - val_loss: 0.0792 - val_mean_absolute_error: 0.0792\n",
            "Epoch 58/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0791 - mean_absolute_error: 0.0791 - val_loss: 0.0762 - val_mean_absolute_error: 0.0762\n",
            "Epoch 59/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0796 - mean_absolute_error: 0.0796 - val_loss: 0.0852 - val_mean_absolute_error: 0.0852\n",
            "Epoch 60/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0799 - mean_absolute_error: 0.0799 - val_loss: 0.0737 - val_mean_absolute_error: 0.0737\n",
            "Epoch 61/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0781 - mean_absolute_error: 0.0781 - val_loss: 0.0744 - val_mean_absolute_error: 0.0744\n",
            "Epoch 62/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0781 - mean_absolute_error: 0.0781 - val_loss: 0.0877 - val_mean_absolute_error: 0.0877\n",
            "Epoch 63/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0780 - mean_absolute_error: 0.0780 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n",
            "Epoch 64/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0785 - mean_absolute_error: 0.0785 - val_loss: 0.0898 - val_mean_absolute_error: 0.0898\n",
            "Epoch 65/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0780 - mean_absolute_error: 0.0780 - val_loss: 0.0805 - val_mean_absolute_error: 0.0805\n",
            "Epoch 66/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0783 - mean_absolute_error: 0.0783 - val_loss: 0.0956 - val_mean_absolute_error: 0.0956\n",
            "Epoch 67/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0793 - mean_absolute_error: 0.0793 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 68/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0787 - mean_absolute_error: 0.0787 - val_loss: 0.0745 - val_mean_absolute_error: 0.0745\n",
            "Epoch 69/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0775 - mean_absolute_error: 0.0775 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 70/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0784 - mean_absolute_error: 0.0784 - val_loss: 0.0735 - val_mean_absolute_error: 0.0735\n",
            "Epoch 71/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0781 - mean_absolute_error: 0.0781 - val_loss: 0.0725 - val_mean_absolute_error: 0.0725\n",
            "Epoch 72/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 73/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0760 - val_mean_absolute_error: 0.0760\n",
            "Epoch 74/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0780 - mean_absolute_error: 0.0780 - val_loss: 0.0810 - val_mean_absolute_error: 0.0810\n",
            "Epoch 75/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0776 - mean_absolute_error: 0.0776 - val_loss: 0.0795 - val_mean_absolute_error: 0.0795\n",
            "Epoch 76/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0782 - mean_absolute_error: 0.0782 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 77/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0815 - val_mean_absolute_error: 0.0815\n",
            "Epoch 78/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0778 - mean_absolute_error: 0.0778 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
            "Epoch 79/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0777 - mean_absolute_error: 0.0777 - val_loss: 0.0742 - val_mean_absolute_error: 0.0742\n",
            "Epoch 80/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0763 - mean_absolute_error: 0.0763 - val_loss: 0.0750 - val_mean_absolute_error: 0.0750\n",
            "Epoch 81/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0776 - mean_absolute_error: 0.0776 - val_loss: 0.0790 - val_mean_absolute_error: 0.0790\n",
            "Epoch 82/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 83/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0748 - val_mean_absolute_error: 0.0748\n",
            "Epoch 84/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0783 - mean_absolute_error: 0.0783 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n",
            "Epoch 85/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0774 - mean_absolute_error: 0.0774 - val_loss: 0.0759 - val_mean_absolute_error: 0.0759\n",
            "Epoch 86/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0773 - mean_absolute_error: 0.0773 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 87/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0776 - mean_absolute_error: 0.0776 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 88/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0776 - mean_absolute_error: 0.0776 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
            "Epoch 89/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0786 - mean_absolute_error: 0.0786 - val_loss: 0.0935 - val_mean_absolute_error: 0.0935\n",
            "Epoch 90/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0769 - mean_absolute_error: 0.0769 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 91/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0767 - mean_absolute_error: 0.0767 - val_loss: 0.0735 - val_mean_absolute_error: 0.0735\n",
            "Epoch 92/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0768 - mean_absolute_error: 0.0768 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 93/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 94/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0768 - mean_absolute_error: 0.0768 - val_loss: 0.0730 - val_mean_absolute_error: 0.0730\n",
            "Epoch 95/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0767 - mean_absolute_error: 0.0767 - val_loss: 0.0743 - val_mean_absolute_error: 0.0743\n",
            "Epoch 96/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0783 - mean_absolute_error: 0.0783 - val_loss: 0.0730 - val_mean_absolute_error: 0.0730\n",
            "Epoch 97/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0769 - mean_absolute_error: 0.0769 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
            "Epoch 98/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0775 - mean_absolute_error: 0.0775 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 99/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0770 - mean_absolute_error: 0.0770 - val_loss: 0.0805 - val_mean_absolute_error: 0.0805\n",
            "Epoch 100/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0774 - mean_absolute_error: 0.0774 - val_loss: 0.0732 - val_mean_absolute_error: 0.0732\n",
            "Epoch 101/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0767 - mean_absolute_error: 0.0767 - val_loss: 0.0767 - val_mean_absolute_error: 0.0767\n",
            "Epoch 102/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0773 - mean_absolute_error: 0.0773 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 103/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0767 - mean_absolute_error: 0.0767 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 104/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0774 - mean_absolute_error: 0.0774 - val_loss: 0.0810 - val_mean_absolute_error: 0.0810\n",
            "Epoch 105/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0765 - mean_absolute_error: 0.0765 - val_loss: 0.0775 - val_mean_absolute_error: 0.0775\n",
            "Epoch 106/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0763 - mean_absolute_error: 0.0763 - val_loss: 0.0761 - val_mean_absolute_error: 0.0761\n",
            "Epoch 107/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0758 - mean_absolute_error: 0.0758 - val_loss: 0.0870 - val_mean_absolute_error: 0.0870\n",
            "Epoch 108/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0776 - mean_absolute_error: 0.0776 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 109/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0769 - mean_absolute_error: 0.0769 - val_loss: 0.0730 - val_mean_absolute_error: 0.0730\n",
            "Epoch 110/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0753 - mean_absolute_error: 0.0753 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
            "Epoch 111/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0769 - mean_absolute_error: 0.0769 - val_loss: 0.0771 - val_mean_absolute_error: 0.0771\n",
            "Epoch 112/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0779 - mean_absolute_error: 0.0779 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 113/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0758 - mean_absolute_error: 0.0758 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 114/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0766 - mean_absolute_error: 0.0766 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
            "Epoch 115/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0761 - mean_absolute_error: 0.0761 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
            "Epoch 116/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0765 - mean_absolute_error: 0.0765 - val_loss: 0.0849 - val_mean_absolute_error: 0.0849\n",
            "Epoch 117/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0769 - mean_absolute_error: 0.0769 - val_loss: 0.0821 - val_mean_absolute_error: 0.0821\n",
            "Epoch 118/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0768 - mean_absolute_error: 0.0768 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
            "Epoch 119/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0764 - mean_absolute_error: 0.0764 - val_loss: 0.0793 - val_mean_absolute_error: 0.0793\n",
            "Epoch 120/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0760 - mean_absolute_error: 0.0760 - val_loss: 0.0765 - val_mean_absolute_error: 0.0765\n",
            "Epoch 121/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0765 - mean_absolute_error: 0.0765 - val_loss: 0.0743 - val_mean_absolute_error: 0.0743\n",
            "Epoch 122/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0758 - mean_absolute_error: 0.0758 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
            "Epoch 123/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0760 - mean_absolute_error: 0.0760 - val_loss: 0.0748 - val_mean_absolute_error: 0.0748\n",
            "Epoch 124/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0762 - mean_absolute_error: 0.0762 - val_loss: 0.0835 - val_mean_absolute_error: 0.0835\n",
            "Epoch 125/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0751 - mean_absolute_error: 0.0751 - val_loss: 0.0750 - val_mean_absolute_error: 0.0750\n",
            "Epoch 126/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0760 - mean_absolute_error: 0.0760 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 127/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0764 - mean_absolute_error: 0.0764 - val_loss: 0.0764 - val_mean_absolute_error: 0.0764\n",
            "Epoch 128/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0756 - mean_absolute_error: 0.0756 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 129/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0752 - mean_absolute_error: 0.0752 - val_loss: 0.0761 - val_mean_absolute_error: 0.0761\n",
            "Epoch 130/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0759 - mean_absolute_error: 0.0759 - val_loss: 0.0732 - val_mean_absolute_error: 0.0732\n",
            "Epoch 131/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0758 - mean_absolute_error: 0.0758 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 132/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0762 - mean_absolute_error: 0.0762 - val_loss: 0.0731 - val_mean_absolute_error: 0.0731\n",
            "Epoch 133/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0753 - mean_absolute_error: 0.0753 - val_loss: 0.0759 - val_mean_absolute_error: 0.0759\n",
            "Epoch 134/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0762 - mean_absolute_error: 0.0762 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 135/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0752 - mean_absolute_error: 0.0752 - val_loss: 0.0756 - val_mean_absolute_error: 0.0756\n",
            "Epoch 136/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0756 - mean_absolute_error: 0.0756 - val_loss: 0.0741 - val_mean_absolute_error: 0.0741\n",
            "Epoch 137/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0749 - mean_absolute_error: 0.0749 - val_loss: 0.0772 - val_mean_absolute_error: 0.0772\n",
            "Epoch 138/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0768 - mean_absolute_error: 0.0768 - val_loss: 0.0752 - val_mean_absolute_error: 0.0752\n",
            "Epoch 139/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0762 - mean_absolute_error: 0.0762 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 140/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0751 - mean_absolute_error: 0.0751 - val_loss: 0.0776 - val_mean_absolute_error: 0.0776\n",
            "Epoch 141/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0755 - mean_absolute_error: 0.0755 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 142/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0754 - mean_absolute_error: 0.0754 - val_loss: 0.0758 - val_mean_absolute_error: 0.0758\n",
            "Epoch 143/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0755 - mean_absolute_error: 0.0755 - val_loss: 0.0829 - val_mean_absolute_error: 0.0829\n",
            "Epoch 144/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0753 - mean_absolute_error: 0.0753 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 145/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0744 - mean_absolute_error: 0.0744 - val_loss: 0.0724 - val_mean_absolute_error: 0.0724\n",
            "Epoch 146/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0745 - mean_absolute_error: 0.0745 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
            "Epoch 147/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0746 - mean_absolute_error: 0.0746 - val_loss: 0.0778 - val_mean_absolute_error: 0.0778\n",
            "Epoch 148/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0738 - mean_absolute_error: 0.0738 - val_loss: 0.0761 - val_mean_absolute_error: 0.0761\n",
            "Epoch 149/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0741 - mean_absolute_error: 0.0741 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
            "Epoch 150/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0745 - mean_absolute_error: 0.0745 - val_loss: 0.0745 - val_mean_absolute_error: 0.0745\n",
            "Epoch 151/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0748 - mean_absolute_error: 0.0748 - val_loss: 0.0730 - val_mean_absolute_error: 0.0730\n",
            "Epoch 152/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0748 - mean_absolute_error: 0.0748 - val_loss: 0.0822 - val_mean_absolute_error: 0.0822\n",
            "Epoch 153/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0745 - mean_absolute_error: 0.0745 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 154/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0744 - mean_absolute_error: 0.0744 - val_loss: 0.0754 - val_mean_absolute_error: 0.0754\n",
            "Epoch 155/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0750 - mean_absolute_error: 0.0750 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 156/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0748 - mean_absolute_error: 0.0748 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 157/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0753 - mean_absolute_error: 0.0753 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 158/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0752 - mean_absolute_error: 0.0752 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 159/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0747 - mean_absolute_error: 0.0747 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 160/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0750 - mean_absolute_error: 0.0750 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 161/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0749 - mean_absolute_error: 0.0749 - val_loss: 0.0761 - val_mean_absolute_error: 0.0761\n",
            "Epoch 162/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0739 - mean_absolute_error: 0.0739 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 163/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0738 - mean_absolute_error: 0.0738 - val_loss: 0.0742 - val_mean_absolute_error: 0.0742\n",
            "Epoch 164/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0747 - mean_absolute_error: 0.0747 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
            "Epoch 165/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0744 - mean_absolute_error: 0.0744 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 166/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0745 - mean_absolute_error: 0.0745 - val_loss: 0.0788 - val_mean_absolute_error: 0.0788\n",
            "Epoch 167/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0745 - mean_absolute_error: 0.0745 - val_loss: 0.0755 - val_mean_absolute_error: 0.0755\n",
            "Epoch 168/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0738 - mean_absolute_error: 0.0738 - val_loss: 0.0700 - val_mean_absolute_error: 0.0700\n",
            "Epoch 169/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0731 - val_mean_absolute_error: 0.0731\n",
            "Epoch 170/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0746 - mean_absolute_error: 0.0746 - val_loss: 0.0779 - val_mean_absolute_error: 0.0779\n",
            "Epoch 171/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0768 - val_mean_absolute_error: 0.0768\n",
            "Epoch 172/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0746 - mean_absolute_error: 0.0746 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
            "Epoch 173/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0742 - val_mean_absolute_error: 0.0742\n",
            "Epoch 174/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0740 - mean_absolute_error: 0.0740 - val_loss: 0.0812 - val_mean_absolute_error: 0.0812\n",
            "Epoch 175/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0744 - mean_absolute_error: 0.0744 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
            "Epoch 176/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0746 - mean_absolute_error: 0.0746 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 177/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 178/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0741 - val_mean_absolute_error: 0.0741\n",
            "Epoch 179/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0740 - mean_absolute_error: 0.0740 - val_loss: 0.0731 - val_mean_absolute_error: 0.0731\n",
            "Epoch 180/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0751 - mean_absolute_error: 0.0751 - val_loss: 0.0745 - val_mean_absolute_error: 0.0745\n",
            "Epoch 181/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0746 - mean_absolute_error: 0.0746 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 182/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0744 - mean_absolute_error: 0.0744 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 183/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0740 - mean_absolute_error: 0.0740 - val_loss: 0.0724 - val_mean_absolute_error: 0.0724\n",
            "Epoch 184/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0752 - mean_absolute_error: 0.0752 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 185/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0739 - mean_absolute_error: 0.0739 - val_loss: 0.0758 - val_mean_absolute_error: 0.0758\n",
            "Epoch 186/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 187/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 188/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0745 - mean_absolute_error: 0.0745 - val_loss: 0.0813 - val_mean_absolute_error: 0.0813\n",
            "Epoch 189/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0750 - mean_absolute_error: 0.0750 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 190/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0741 - mean_absolute_error: 0.0741 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 191/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0744 - mean_absolute_error: 0.0744 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 192/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 193/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 194/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0740 - mean_absolute_error: 0.0740 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 195/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 196/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 197/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 198/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - val_loss: 0.0737 - val_mean_absolute_error: 0.0737\n",
            "Epoch 199/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0735 - val_mean_absolute_error: 0.0735\n",
            "Epoch 200/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0738 - mean_absolute_error: 0.0738 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 201/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 202/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - val_loss: 0.0724 - val_mean_absolute_error: 0.0724\n",
            "Epoch 203/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0742 - mean_absolute_error: 0.0742 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 204/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 205/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0737 - mean_absolute_error: 0.0737 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 206/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 207/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0738 - mean_absolute_error: 0.0738 - val_loss: 0.0728 - val_mean_absolute_error: 0.0728\n",
            "Epoch 208/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 209/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0743 - mean_absolute_error: 0.0743 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 210/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 211/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 212/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0732 - val_mean_absolute_error: 0.0732\n",
            "Epoch 213/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0745 - mean_absolute_error: 0.0745 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n",
            "Epoch 214/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 215/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 216/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0735 - val_mean_absolute_error: 0.0735\n",
            "Epoch 217/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0737 - mean_absolute_error: 0.0737 - val_loss: 0.0710 - val_mean_absolute_error: 0.0710\n",
            "Epoch 218/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
            "Epoch 219/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - val_loss: 0.0728 - val_mean_absolute_error: 0.0728\n",
            "Epoch 220/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 221/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 222/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 223/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
            "Epoch 224/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0737 - mean_absolute_error: 0.0737 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 225/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 226/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 227/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 228/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 229/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 230/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0743 - val_mean_absolute_error: 0.0743\n",
            "Epoch 231/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 232/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 233/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 234/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 235/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 236/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 237/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 238/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0698 - val_mean_absolute_error: 0.0698\n",
            "Epoch 239/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 240/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0698 - val_mean_absolute_error: 0.0698\n",
            "Epoch 241/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 242/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
            "Epoch 243/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 244/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 245/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0754 - val_mean_absolute_error: 0.0754\n",
            "Epoch 246/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 247/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0743 - val_mean_absolute_error: 0.0743\n",
            "Epoch 248/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 249/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 250/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
            "Epoch 251/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 252/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 253/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 254/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0741 - mean_absolute_error: 0.0741 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 255/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 256/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 257/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 258/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0700 - val_mean_absolute_error: 0.0700\n",
            "Epoch 259/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 260/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 261/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 262/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 263/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0710 - val_mean_absolute_error: 0.0710\n",
            "Epoch 264/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 265/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 266/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 267/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 268/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 269/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 270/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 271/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 272/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 273/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0735 - val_mean_absolute_error: 0.0735\n",
            "Epoch 274/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 275/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 276/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 277/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 278/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0744 - val_mean_absolute_error: 0.0744\n",
            "Epoch 279/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 280/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 281/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 282/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 283/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 284/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0737 - mean_absolute_error: 0.0737 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 285/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 286/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 287/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 288/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n",
            "Epoch 289/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 290/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 291/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 292/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 293/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 294/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 295/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0710 - val_mean_absolute_error: 0.0710\n",
            "Epoch 296/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 297/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 298/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0756 - val_mean_absolute_error: 0.0756\n",
            "Epoch 299/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 300/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 301/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 302/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 303/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 304/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 305/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 306/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 307/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 308/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 309/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
            "Epoch 310/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 311/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0737 - mean_absolute_error: 0.0737 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 312/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 313/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 314/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 315/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 316/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
            "Epoch 317/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 318/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 319/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 320/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0710 - val_mean_absolute_error: 0.0710\n",
            "Epoch 321/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 322/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 323/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 324/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 325/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 326/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 327/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 328/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 329/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 330/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0741 - mean_absolute_error: 0.0741 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 331/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 332/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 333/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0725 - val_mean_absolute_error: 0.0725\n",
            "Epoch 334/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0734 - mean_absolute_error: 0.0734 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 335/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 336/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 337/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 338/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 339/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0717 - mean_absolute_error: 0.0717 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 340/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0728 - val_mean_absolute_error: 0.0728\n",
            "Epoch 341/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 342/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0713 - mean_absolute_error: 0.0713 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 343/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 344/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 345/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 346/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 347/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 348/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 349/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 350/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 351/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 352/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0719 - mean_absolute_error: 0.0719 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 353/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 354/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 355/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 356/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 357/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
            "Epoch 358/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 359/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 360/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 361/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 362/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 363/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 364/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 365/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 366/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 367/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 368/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 369/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 370/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.0735 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 371/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 372/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 373/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0724 - val_mean_absolute_error: 0.0724\n",
            "Epoch 374/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
            "Epoch 375/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 376/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 377/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 378/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 379/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0732 - mean_absolute_error: 0.0732 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 380/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 381/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 382/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 383/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 384/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 385/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 386/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 387/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 388/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 389/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0719 - mean_absolute_error: 0.0719 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 390/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 391/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 392/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 393/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0718 - mean_absolute_error: 0.0718 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 394/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 395/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 396/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 397/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
            "Epoch 398/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0700 - val_mean_absolute_error: 0.0700\n",
            "Epoch 399/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 400/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 401/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 402/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 403/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 404/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 405/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0717 - mean_absolute_error: 0.0717 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 406/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0736 - mean_absolute_error: 0.0736 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 407/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 408/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 409/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0718 - mean_absolute_error: 0.0718 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 410/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 411/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 412/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0719 - mean_absolute_error: 0.0719 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 413/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0731 - mean_absolute_error: 0.0731 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 414/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 415/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 416/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 417/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 418/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 419/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 420/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 421/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 422/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 423/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 424/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 425/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 426/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 427/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 428/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 429/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 430/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0724 - val_mean_absolute_error: 0.0724\n",
            "Epoch 431/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 432/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 433/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0718 - mean_absolute_error: 0.0718 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 434/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 435/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0761 - val_mean_absolute_error: 0.0761\n",
            "Epoch 436/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 437/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 438/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
            "Epoch 439/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0715 - mean_absolute_error: 0.0715 - val_loss: 0.0718 - val_mean_absolute_error: 0.0718\n",
            "Epoch 440/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0696 - val_mean_absolute_error: 0.0696\n",
            "Epoch 441/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 442/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 443/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 444/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.0724 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n",
            "Epoch 445/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 446/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0718 - mean_absolute_error: 0.0718 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 447/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 448/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 449/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0716 - mean_absolute_error: 0.0716 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 450/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 451/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
            "Epoch 452/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 453/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 454/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0710 - val_mean_absolute_error: 0.0710\n",
            "Epoch 455/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 456/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0700 - val_mean_absolute_error: 0.0700\n",
            "Epoch 457/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 458/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0714 - mean_absolute_error: 0.0714 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 459/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0718 - mean_absolute_error: 0.0718 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 460/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 461/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0729 - mean_absolute_error: 0.0729 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 462/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0710 - val_mean_absolute_error: 0.0710\n",
            "Epoch 463/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 464/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0707 - val_mean_absolute_error: 0.0707\n",
            "Epoch 465/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 466/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 467/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 468/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
            "Epoch 469/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 470/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0726 - mean_absolute_error: 0.0726 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 471/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0719 - mean_absolute_error: 0.0719 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 472/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0702 - val_mean_absolute_error: 0.0702\n",
            "Epoch 473/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0715 - mean_absolute_error: 0.0715 - val_loss: 0.0703 - val_mean_absolute_error: 0.0703\n",
            "Epoch 474/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0712 - val_mean_absolute_error: 0.0712\n",
            "Epoch 475/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0716 - mean_absolute_error: 0.0716 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 476/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0717 - mean_absolute_error: 0.0717 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 477/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0719 - mean_absolute_error: 0.0719 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 478/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 479/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 480/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 481/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 482/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0711 - val_mean_absolute_error: 0.0711\n",
            "Epoch 483/500\n",
            "569/569 [==============================] - 2s 4ms/step - loss: 0.0728 - mean_absolute_error: 0.0728 - val_loss: 0.0773 - val_mean_absolute_error: 0.0773\n",
            "Epoch 484/500\n",
            "569/569 [==============================] - 2s 4ms/step - loss: 0.0733 - mean_absolute_error: 0.0733 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 485/500\n",
            "569/569 [==============================] - 2s 4ms/step - loss: 0.0719 - mean_absolute_error: 0.0719 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 486/500\n",
            "569/569 [==============================] - 2s 4ms/step - loss: 0.0727 - mean_absolute_error: 0.0727 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 487/500\n",
            "569/569 [==============================] - 2s 4ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0701 - val_mean_absolute_error: 0.0701\n",
            "Epoch 488/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 489/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0717 - mean_absolute_error: 0.0717 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 490/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 491/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 492/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 493/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 494/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0717 - mean_absolute_error: 0.0717 - val_loss: 0.0698 - val_mean_absolute_error: 0.0698\n",
            "Epoch 495/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 496/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0716 - mean_absolute_error: 0.0716 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 497/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.0722 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 498/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0720 - mean_absolute_error: 0.0720 - val_loss: 0.0713 - val_mean_absolute_error: 0.0713\n",
            "Epoch 499/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0721 - mean_absolute_error: 0.0721 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 500/500\n",
            "569/569 [==============================] - 2s 3ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0721 - val_mean_absolute_error: 0.0721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kWWqjJvFGV2"
      },
      "source": [
        "def plot(data,string):\n",
        "  plt.plot(data.history[string])\n",
        "  plt.plot(data.history[\"val_\"+string])\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string,\"val_\"+string])\n",
        "  plt.show()\n"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXfm7xfzGjvd",
        "outputId": "00d75901-6aa4-49b7-a080-0ebabaaf7049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot(history,\"mean_absolute_error\")"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqo4lq4HGmnp",
        "outputId": "25665974-44b6-489c-99b2-1f89e75a214d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "train_pred=model.predict(only_train_data)\n",
        "val_pred=model.predict(val_data)\n",
        "train_r2=r2_score(train_pred,only_train_score)\n",
        "val_r2=r2_score(val_pred,val_burn_rate)\n",
        "print(train_r2)\n",
        "print(val_r2)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6483805115976863\n",
            "0.5524148575051177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKu8fw6_CO0k",
        "outputId": "1f2d275b-9244-43b9-b90d-68a5246acee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_main_data_set"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Designation</th>\n",
              "      <th>Resource Allocation</th>\n",
              "      <th>Mental Fatigue Score</th>\n",
              "      <th>WFH Setup Available value</th>\n",
              "      <th>Sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12245</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12246</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12247</th>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12248</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12249</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12250 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Designation  Resource Allocation  ...  WFH Setup Available value  Sex\n",
              "0              2.0                  5.0  ...                          0    0\n",
              "1              1.0                  2.0  ...                          1    0\n",
              "2              1.0                  3.0  ...                          1    1\n",
              "3              3.0                  6.0  ...                          0    0\n",
              "4              2.0                  5.0  ...                          0    0\n",
              "...            ...                  ...  ...                        ...  ...\n",
              "12245          1.0                  2.0  ...                          1    0\n",
              "12246          2.0                  4.0  ...                          1    0\n",
              "12247          4.0                  7.0  ...                          0    1\n",
              "12248          3.0                  6.0  ...                          0    1\n",
              "12249          2.0                  2.0  ...                          0    0\n",
              "\n",
              "[12250 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBA7Kr6rDpWB"
      },
      "source": [
        "burn_rate_pred=model.predict(test_main_data_set)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vypKK4BMZvw2"
      },
      "source": [
        "result=pd.DataFrame()\n"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMb2se7fZodq"
      },
      "source": [
        "result[\"Employee ID\"]=test_data[\"Employee ID\"]\n",
        "result[\"Burn Rate\"]=burn_rate_pred"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rsh33VdabLB",
        "outputId": "1e3404ab-0f4e-4103-c793-1ae831b7d0db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QphpXg2rafMm"
      },
      "source": [
        "result.to_csv('/content/drive/My Drive/Hacker_Earth_Burn_out_rate.csv',index=False)"
      ],
      "execution_count": 183,
      "outputs": []
    }
  ]
}